# 第3章 为图像生成标注

 字幕生成是深度学习领域中最重要的应用之一，近年来得到了广泛的关注。图像字幕模型涉及到视觉信息和自然语言处理的结合。  在本章中，我们将了解：  标题生成领域的最新进展。  标题生成是如何工作的。  标题生成模型的实现。  什么是字幕生成？  标题生成是用自然语言描述图像的任务。以前，标题生成模型使用对象检测模型与用于为检测到的对象生成文本的模板相结合。随着深度学习的发展，这些模型已经被卷积神经网络和递归神经网络的结合所取代。  一个例子如下：  有几个数据集帮助我们创建图像标题模型。  图像字幕数据集的探索。  有几个数据集可用于标题图像任务。数据集通常是通过向几个人显示一幅图像并要求他们每个人写一个关于该图像的句子来准备的。通过该方法，为同一图像生成多个标题。有多个标题选项有助于更好地概括。难点在于模型性能的排序。对于每一代，最好，人类必须评估标题。对于这项任务，自动评估是很困难的。让我们研究一下Flickr 8数据集。  下载数据集。  Flickr 8是从Flickr收集的，不允许用于商业用途。从https：/forms.illinois.edu/sec/171339 8下载Flickr 8数据集。这些说明可查阅http：/nlp.cs.illinois.edu/hockenemyergroup/8k-图片.htm 1。分别下载文本和图像。可通过填写页面上显示的表格获得访问权限：  电子邮件将与下载链接一起发送。下载并解压缩后，文件应该如下所示：  下面是DataSet中给出的两个示例：  下图显示了以下组件：  一名身穿街头赛车盔甲的男子正在检查另一名赛车手的轮胎。  两位赛车手把白色的自行车开在路上。  两名驾车者正骑着设计奇特、颜色奇特的汽车行驶。  两个人坐在一辆小型赛车上，驶过一座绿色的小山。  两个人穿着赛车制服坐在一辆街车里。  下面是示例2：  下图显示了以下组件：  一个穿着黑色连帽衫和牛仔裤的男子沿着栏杆滑着滑板。  一名男子沿着陡峭的栏杆滑下一些台阶。  一个人滑下滑雪板上的砖头栏杆。  一个人走下一组台阶附近的砖栏杆滑雪板滑雪者在没有雪的情况下滑下扶手。  如您所见，有不同的标题为一个图像提供。字幕显示了图像字幕任务的难度。  将单词转换为嵌入。  为了生成标题，英语单词必须转换为嵌入。嵌入只不过是文字或图像的矢量或数字表示。如果将单词转换为向量形式，这样就可以使用这些向量执行算术运算，这是很有用的。  这种嵌入可以通过两种方法学习，如下图所示：  CBOW方法通过预测给定周围单词的单词来学习嵌入。Skip-gram方法对给定单词的周围词进行预测，这与CBOW方法相反.。根据历史，可以对目标词进行培训，如下图所示：  一旦培训，嵌入可以可视化如下：  这种类型的嵌入可以用来执行字的向量运算。在本章中，这个词嵌入的概念将是有帮助的。  图像字幕方法。  有几种方法，以标题图像。以前的方法用于根据图像中存在的对象和属性构造句子。再利用递归神经网络(RNN)生成句子。最精确的方法是使用注意机制。让我们在本节中详细探讨这些技术和结果。 

条件随机场。
首先尝试了一种利用条件随机场(CRF)构造句子的方法，该方法利用图像中检测到的对象和属性来构造句子。这一过程所涉及的步骤如下：
示例映像的系统流(来源：http：//www.tamaraberg.com/papers/generation_cvpr11.pdf))。
CRF以连贯的方式造出句子的能力有限。生成的句子质量不高，如以下截图所示：
尽管对象和属性正确，但是这里显示的句子太结构化了。
Kulkarni等人在论文http：/www.tamaraberg.com/Papers/Generationcvpr11.pdf中提出了一种从图像中找出对象和属性并利用其生成具有条件随机场(CRF)的文本的方法。
基于卷积神经网络的递归神经网络。
递归神经网络可与卷积神经网络特征相结合，生成新的句子。这使模型的端到端培训成为可能。以下是该模型的体系结构：
LSTM模型(来源：https：/arxiv.org/pdf/1411.4555.pdf)。
有几层LSTM用于产生所需的结果。以下截图显示了该模型产生的一些结果：
这些结果优于CRF的结果。这说明了LSTM在生成句子方面的强大功能。
参考文献：Vinyals等人，载于文件https：/arxiv.org/pdf/1411。4555.PDF，提议对图像字幕进行端到端可训练的深度学习，将CNN和RNN背对背地堆叠起来。
标题排名。
标题排名是从一组标题中选择标题的有趣方法。首先，根据图像的特征对图像进行排序，并选择相应的标题，如以下截图所示：
资料来源：http：//papers.nips.cc/paper/4470-im2text-describing-images-using-1-million-captioned-photographs.pdf。
可以使用一组不同的属性对顶部图像进行重新排序。通过获得更多的图像，质量可以提高很多，如以下截图所示：
资料来源：http：//papers.nips.cc/paper/4470-im2text-describing-images-using-1-million-captioned-photographs.pdf。
随着数据集中图像数量的增加，结果会更好。
欲了解更多有关标题排名的信息，请参阅http：/pas.nips.cc/纸面/4470-im2text-描述-图像-使用-100万-标题图片。pd f。
密集字幕。
密集字幕是一个图像上的多个字幕的问题。以下是该问题的体系结构：
资料来源：https：//www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.pdf。
这种架构产生了良好的效果。
如需更多了解，请参阅：johnson等人的文章https：/www.cv-Foundation.org/openaccess/Content_CVPR_2016/Papers/Johnson_DenseCapFall_ConvolativeCVPR_2016_Paper.Pdf，提出了一种密集字幕的方法。
RNN字幕。
视觉特征可以与序列学习一起使用，形成输出。
这是一种用于生成标题的体系结构。
详情请参阅：Donahue等人，载于文件https：/arxiv.org/pdf/1411。4389.pd f，提出了用于图像字幕的长期递归卷积结构(LRCN)。
多模态字幕。
图像和文本都可以映射到相同的嵌入空间以生成标题。
需要解码器来生成标题。
基于注意的字幕。
详情请参阅：徐等人，在本文中，https：/arxiv.org/pdf/1502.03044。
提出了一种基于注意机制的图像字幕处理方法。
基于注意力的字幕最近变得流行起来，因为它提供了更好的准确性：
这种方法按照标题的顺序训练注意力模型，从而产生更好的结果：
下面是一个LSTM的图表，上面有一些引起注意的标题：
这里展示了几个示例，其中以时间序列的方式展现了对象的出色可视化：
结果真的很好！

 实现标题生成模型。  首先，让我们读取数据集并按照我们需要的方式进行转换。导入os库并声明数据集所在的目录，如下代码所示：   接下来，定义一个函数来打开文件并将文件中的行作为列表返回：  阅读以下标题文件后面的培训和测试数据集的图像路径：  这应打印如下：  接下来，必须生成图像到标题的映射。这将有助于训练，便于查找标题。此外，标题数据集中的独特单词将有助于创建词汇表：   现在，必须形成两张地图。一个是从字到索引，另一个是从字到图：  现在创建ImageModel类，以便用权重加载VGG模型：  下载并存储权重。第一次尝试可能需要一些时间。接下来，创建一个单独的模型，以便预测第二个完全连接的层。以下是从路径读取图像并进行预处理的方法：   接下来，定义一个加载图像并进行预测的方法。预测的第二完全连接层可以被重新塑造为4096：  浏览一个图像路径列表并创建一个特性列表：  接下来，将提取的特性存储为一个泡菜文件：  导入构建模型所需的层：  获得所需的词汇量：  对于该语言，将创建一个模型：  这个模型可以被训练来产生标题。  摘要。  在本章中，我们学习了图像字幕技术。首先，我们了解了词向量的嵌入空间。然后，对几种图像字幕处理方法进行了研究。接着是图像字幕模型的实现。  在下一章中，我们将研究生成对抗网络(GAN)的概念。甘斯是耐人寻味的和有用的，以产生各种用途的图像。 